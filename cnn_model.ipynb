{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nommrichard/prod_rating/blob/main/rnn_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lx3kNA5QObSX"
      },
      "source": [
        "# Predicting product rating based on review text \n",
        "\n",
        "## Project in LTAT.01.001 Natural language processing\n",
        "\n",
        "#### Team members: Karl Jaagup Kask, Ludvig Leis, Richard NÃµmm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OR2En_bNOKIh",
        "outputId": "b8b5e46c-a614-466e-a347-8d37f81399a1"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re \n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "!python3 -m nltk.downloader stopwords\n",
        "!python3 -m nltk.downloader punkt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.7/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "/usr/lib/python3.7/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjSLi-TpZcXb"
      },
      "source": [
        "RANDOM_SEED = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7z9_NwhNOpLR"
      },
      "source": [
        "The data we are using: https://www.kaggle.com/datafiniti/consumer-reviews-of-amazon-products"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwCm46NbOTIg"
      },
      "source": [
        "## Data preprocessing (data file needs to be imported)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdUOTKUiOOKR"
      },
      "source": [
        "df = pd.read_csv('amazon_review_dataset.csv') #renamed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHrZGSNuOPpA",
        "outputId": "768f5b82-c3f2-4f92-fd9f-e1669350b385"
      },
      "source": [
        "df = df[df['reviews.rating'].notnull() & df['reviews.text'].notnull()]\n",
        "df= df[['reviews.rating','reviews.text']]\n",
        "\n",
        "df.rename(columns = {'reviews.rating':'rating', 'reviews.text':'text'}, inplace = True)\n",
        "df['text'][0]\n",
        "cleaned = df['text']\n",
        "print(cleaned[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I order 3 of them and one of the item is bad quality. Is missing backup spring so I have to put a pcs of aluminum to make the battery work.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RYhoqoOZOSWw",
        "outputId": "47c27d4a-4db4-4b2b-d8fc-66e6aecbb32f"
      },
      "source": [
        "\n",
        "stops = stopwords.words('english')\n",
        "\n",
        "remove_punc = re.compile('[^a-z]+')\n",
        "def clean_text(sent):\n",
        "    sent = str(sent).lower()\n",
        "    sent = remove_punc.sub(' ', sent).strip()\n",
        "    filtered = [word for word in sent.split()]\n",
        "    sentence = \" \".join(filtered) #just joined -> laused\n",
        "  \n",
        "    #sentence = nltk.word_tokenize(sentence) #tokenized -> listid\n",
        "    return sentence\n",
        "\n",
        "\n",
        "clean_text(df['text'][0])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'i order of them and one of the item is bad quality is missing backup spring so i have to put a pcs of aluminum to make the battery work'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPb6ydqJQAQR"
      },
      "source": [
        "reviews = [clean_text(sent) for sent in df['text']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "xBzW0mm7VzJz",
        "outputId": "7009a98b-3461-4f71-dd3a-e7951b806cb5"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>I order 3 of them and one of the item is bad q...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>Bulk is always the less expensive way to go fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>Well they are not Duracell but for the price i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>Seem to work as well as name brand batteries a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>These batteries are very long lasting the pric...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rating                                               text\n",
              "0       3  I order 3 of them and one of the item is bad q...\n",
              "1       4  Bulk is always the less expensive way to go fo...\n",
              "2       5  Well they are not Duracell but for the price i...\n",
              "3       5  Seem to work as well as name brand batteries a...\n",
              "4       5  These batteries are very long lasting the pric..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9nwsaIXVzt8"
      },
      "source": [
        "## I CNN approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "RSCZhJCZWfJF",
        "outputId": "54d09021-080b-4db5-ded3-69531414a011"
      },
      "source": [
        "y = pd.get_dummies(df.rating, prefix='rating_')\n",
        "y.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating__1</th>\n",
              "      <th>rating__2</th>\n",
              "      <th>rating__3</th>\n",
              "      <th>rating__4</th>\n",
              "      <th>rating__5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rating__1  rating__2  rating__3  rating__4  rating__5\n",
              "0          0          0          1          0          0\n",
              "1          0          0          0          1          0\n",
              "2          0          0          0          0          1\n",
              "3          0          0          0          0          1\n",
              "4          0          0          0          0          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuhcI1RKlhsd"
      },
      "source": [
        "import string\n",
        "\n",
        "def clean_document(doco):\n",
        "    punctuation = string.punctuation + '\\n\\n';\n",
        "    punc_replace = ''.join([' ' for s in punctuation]);\n",
        "    doco_clean = doco.replace('-', ' ');\n",
        "    doco_alphas = re.sub(r'\\W +', '', doco_clean)\n",
        "    trans_table = str.maketrans(punctuation, punc_replace);\n",
        "    doco_clean = ' '.join([word.translate(trans_table) for word in doco_alphas.split(' ')]);\n",
        "    doco_clean = doco_clean.split(' ');\n",
        "    doco_clean = [word.lower() for word in doco_clean if len(word) > 0];\n",
        "    \n",
        "    return doco_clean;\n",
        "\n",
        "# Generate a cleaned reviews array from original review texts\n",
        "review_cleans = [clean_document(doc) for doc in reviews];\n",
        "sentences = [' '.join(r) for r in review_cleans]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4qjrFMcWxZk",
        "outputId": "23fcd885-a627-4fbf-bc11-f45a8d84a3e7"
      },
      "source": [
        "print(sentences[0:2])\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.backend import eval\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.convolutional import Conv1D,MaxPooling1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(sentences, y.values, test_size=0.20, random_state=42)\n",
        "\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "maxlen = 200\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['order one item bad quality missing backup spring put pcs aluminum make battery work', 'bulk always less expensive way go products like']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cu6_hA5BxlA-",
        "outputId": "09f26294-a529-4fa1-bbcc-a3825c7e404d"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
        "\n",
        "model = Sequential()      # initilaizing the Sequential nature for CNN model\n",
        "model.add(Embedding(5000, 32, input_length=maxlen))\n",
        "model.add(Conv1D(32, 3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(250, activation='relu'))\n",
        "model.add(Dense(5, activation='sigmoid'))\n",
        "\n",
        "'''model = Sequential()\n",
        "model.add(Embedding(5000, 100, input_length=maxlen))\n",
        "model.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(5, activation='sigmoid'))'''\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=128, verbose=2, callbacks=[es])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "178/178 - 10s - loss: 0.3060 - accuracy: 0.7002 - val_loss: 0.2647 - val_accuracy: 0.7233\n",
            "Epoch 2/5\n",
            "178/178 - 9s - loss: 0.2375 - accuracy: 0.7467 - val_loss: 0.2375 - val_accuracy: 0.7521\n",
            "Epoch 3/5\n",
            "178/178 - 9s - loss: 0.1961 - accuracy: 0.7970 - val_loss: 0.2255 - val_accuracy: 0.7702\n",
            "Epoch 4/5\n",
            "178/178 - 9s - loss: 0.1636 - accuracy: 0.8356 - val_loss: 0.2191 - val_accuracy: 0.7860\n",
            "Epoch 5/5\n",
            "178/178 - 9s - loss: 0.1314 - accuracy: 0.8734 - val_loss: 0.2219 - val_accuracy: 0.7992\n",
            "Epoch 00005: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3ecd6a0a50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHNbs7gKgcH5",
        "outputId": "63212b7e-4fbb-437e-fbe7-7a9cbecf24ca"
      },
      "source": [
        "score = model.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy: %0.4f%%\" % (score[1]*100))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "178/178 [==============================] - 1s 6ms/step - loss: 0.2219 - accuracy: 0.7992\n",
            "Test accuracy: 79.9188%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuUqJvNIuETx"
      },
      "source": [
        "## II CNN approach (removed stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUiRw7-Rr_cu",
        "outputId": "0d5c44da-fe14-4f1d-d061-56c3b6467814"
      },
      "source": [
        "# with stopwords\n",
        "df = pd.read_csv('amazon_review_dataset.csv') #renamed\n",
        "df = df[df['reviews.rating'].notnull() & df['reviews.text'].notnull()]\n",
        "df= df[['reviews.rating','reviews.text']]\n",
        "\n",
        "df.rename(columns = {'reviews.rating':'rating', 'reviews.text':'text'}, inplace = True)\n",
        "df['text'][0]\n",
        "cleaned = df['text']\n",
        "print(cleaned[0])\n",
        "stops = stopwords.words('english')\n",
        "\n",
        "remove_punc = re.compile('[^a-z]+')\n",
        "def clean_text(sent):\n",
        "    sent = str(sent).lower()\n",
        "    sent = remove_punc.sub(' ', sent).strip()\n",
        "    filtered = [word for word in sent.split() if word not in stops]\n",
        "    sentence = \" \".join(filtered) #just joined -> laused\n",
        "  \n",
        "    #sentence = nltk.word_tokenize(sentence) #tokenized -> listid\n",
        "    return sentence\n",
        "\n",
        "\n",
        "clean_text(df['text'][0])\n",
        "reviews = [clean_text(sent) for sent in df['text']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I order 3 of them and one of the item is bad quality. Is missing backup spring so I have to put a pcs of aluminum to make the battery work.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "0U813IxnsVy_",
        "outputId": "afe8e1cc-7845-4206-ba3f-f9bcf459df66"
      },
      "source": [
        "df['text'] = reviews\n",
        "df.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>order one item bad quality missing backup spri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>bulk always less expensive way go products like</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>well duracell price happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>seem work well name brand batteries much bette...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>batteries long lasting price great</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rating                                               text\n",
              "0       3  order one item bad quality missing backup spri...\n",
              "1       4    bulk always less expensive way go products like\n",
              "2       5                          well duracell price happy\n",
              "3       5  seem work well name brand batteries much bette...\n",
              "4       5                 batteries long lasting price great"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTZz5GN2sWFQ"
      },
      "source": [
        "y = pd.get_dummies(df.rating, prefix='rating_')\n",
        "def clean_document(doco):\n",
        "    punctuation = string.punctuation + '\\n\\n';\n",
        "    punc_replace = ''.join([' ' for s in punctuation]);\n",
        "    doco_clean = doco.replace('-', ' ');\n",
        "    doco_alphas = re.sub(r'\\W +', '', doco_clean)\n",
        "    trans_table = str.maketrans(punctuation, punc_replace);\n",
        "    doco_clean = ' '.join([word.translate(trans_table) for word in doco_alphas.split(' ')]);\n",
        "    doco_clean = doco_clean.split(' ');\n",
        "    doco_clean = [word.lower() for word in doco_clean if len(word) > 0];\n",
        "    \n",
        "    return doco_clean;\n",
        "\n",
        "# Generate a cleaned reviews array from original review texts\n",
        "#review_cleans = [clean_document(doc) for doc in reviews];\n",
        "#sentences = [' '.join(r) for r in review_cleans]\n",
        "sentences = [' '.join(r) for r in reviews]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZbiUrIZspUX"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(reviews, y.values, test_size=0.20, random_state=42)\n",
        "\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "maxlen = 200\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wmq4w8Nsx3ed",
        "outputId": "4c09a7c0-8830-44f6-cf02-f4c0ee69c835"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
        "import tensorflow as tf\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
        "\n",
        "model = Sequential()      # initilaizing the Sequential nature for CNN model\n",
        "model.add(Embedding(5000, 32, input_length=maxlen))\n",
        "model.add(Conv1D(32, 3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(250, activation='relu'))\n",
        "model.add(Dense(5, activation='sigmoid'))\n",
        "\n",
        "'''model = Sequential()\n",
        "model.add(Embedding(5000, 100, input_length=maxlen))\n",
        "model.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(5, activation='sigmoid'))'''\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=128, verbose=2, callbacks=[es])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "178/178 - 10s - loss: 0.3040 - accuracy: 0.7009 - val_loss: 0.2662 - val_accuracy: 0.7238\n",
            "Epoch 2/10\n",
            "178/178 - 9s - loss: 0.2352 - accuracy: 0.7492 - val_loss: 0.2394 - val_accuracy: 0.7514\n",
            "Epoch 3/10\n",
            "178/178 - 9s - loss: 0.1962 - accuracy: 0.7984 - val_loss: 0.2255 - val_accuracy: 0.7683\n",
            "Epoch 4/10\n",
            "178/178 - 9s - loss: 0.1623 - accuracy: 0.8371 - val_loss: 0.2199 - val_accuracy: 0.7867\n",
            "Epoch 5/10\n",
            "178/178 - 9s - loss: 0.1312 - accuracy: 0.8739 - val_loss: 0.2208 - val_accuracy: 0.8004\n",
            "Epoch 00005: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3ecd6fce10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx4i2uYJszU-",
        "outputId": "df87d373-37d1-4512-83ba-da1b71b61837"
      },
      "source": [
        "score = model.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy: %0.4f%%\" % (score[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "178/178 [==============================] - 1s 6ms/step - loss: 0.2208 - accuracy: 0.8004\n",
            "Test accuracy: 80.0424%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUf6V47UuP5r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}