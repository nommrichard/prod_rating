{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nommrichard/prod_rating/blob/main/rnn_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lx3kNA5QObSX"
      },
      "source": [
        "# Predicting product rating based on review text \n",
        "\n",
        "## Project in LTAT.01.001 Natural language processing\n",
        "\n",
        "#### Team members: Karl Jaagup Kask, Ludvig Leis, Richard NÃµmm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OR2En_bNOKIh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee30dc20-f0f4-47be-89f5-3fa32a93a72f"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re \n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "!python3 -m nltk.downloader stopwords\n",
        "!python3 -m nltk.downloader punkt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.7/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "/usr/lib/python3.7/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjSLi-TpZcXb"
      },
      "source": [
        "RANDOM_SEED = 100"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7z9_NwhNOpLR"
      },
      "source": [
        "The data we are using: https://www.kaggle.com/datafiniti/consumer-reviews-of-amazon-products"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwCm46NbOTIg"
      },
      "source": [
        "## Data preprocessing (data file needs to be imported)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdUOTKUiOOKR"
      },
      "source": [
        "df = pd.read_csv('amazon_review_dataset.csv') #renamed"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHrZGSNuOPpA",
        "outputId": "3c230a76-44c4-4272-d68b-bfe5d1baf9ac"
      },
      "source": [
        "df = df[df['reviews.rating'].notnull() & df['reviews.text'].notnull()]\n",
        "df= df[['reviews.rating','reviews.text']]\n",
        "\n",
        "df.rename(columns = {'reviews.rating':'rating', 'reviews.text':'text'}, inplace = True)\n",
        "df['text'][0]\n",
        "cleaned = df['text']\n",
        "print(cleaned[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I order 3 of them and one of the item is bad quality. Is missing backup spring so I have to put a pcs of aluminum to make the battery work.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYhoqoOZOSWw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b3b60bd3-ce8d-4dda-a1b7-98da0355fc57"
      },
      "source": [
        "\n",
        "stops = stopwords.words('english')\n",
        "\n",
        "remove_punc = re.compile('[^a-z]+')\n",
        "def clean_text(sent):\n",
        "    sent = str(sent).lower()\n",
        "    sent = remove_punc.sub(' ', sent).strip()\n",
        "    filtered = [word for word in sent.split()]\n",
        "    sentence = \" \".join(filtered) #just joined -> laused\n",
        "  \n",
        "    #sentence = nltk.word_tokenize(sentence) #tokenized -> listid\n",
        "    return sentence\n",
        "\n",
        "\n",
        "clean_text(df['text'][0])\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'i order of them and one of the item is bad quality is missing backup spring so i have to put a pcs of aluminum to make the battery work'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPb6ydqJQAQR"
      },
      "source": [
        "reviews = [clean_text(sent) for sent in df['text']]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBzW0mm7VzJz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e548b36a-dc37-4f82-cb4d-2f20ca4a1a54"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>I order 3 of them and one of the item is bad q...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>Bulk is always the less expensive way to go fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>Well they are not Duracell but for the price i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>Seem to work as well as name brand batteries a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>These batteries are very long lasting the pric...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rating                                               text\n",
              "0       3  I order 3 of them and one of the item is bad q...\n",
              "1       4  Bulk is always the less expensive way to go fo...\n",
              "2       5  Well they are not Duracell but for the price i...\n",
              "3       5  Seem to work as well as name brand batteries a...\n",
              "4       5  These batteries are very long lasting the pric..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9nwsaIXVzt8"
      },
      "source": [
        "## I RNN approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "RSCZhJCZWfJF",
        "outputId": "aa0bf863-f42c-41a2-c923-89fd7fb9cbe5"
      },
      "source": [
        "y = pd.get_dummies(df.rating, prefix='rating_')\n",
        "y.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating__1</th>\n",
              "      <th>rating__2</th>\n",
              "      <th>rating__3</th>\n",
              "      <th>rating__4</th>\n",
              "      <th>rating__5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rating__1  rating__2  rating__3  rating__4  rating__5\n",
              "0          0          0          1          0          0\n",
              "1          0          0          0          1          0\n",
              "2          0          0          0          0          1\n",
              "3          0          0          0          0          1\n",
              "4          0          0          0          0          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuhcI1RKlhsd"
      },
      "source": [
        "import string\n",
        "\n",
        "def clean_document(doco):\n",
        "    punctuation = string.punctuation + '\\n\\n';\n",
        "    punc_replace = ''.join([' ' for s in punctuation]);\n",
        "    doco_clean = doco.replace('-', ' ');\n",
        "    doco_alphas = re.sub(r'\\W +', '', doco_clean)\n",
        "    trans_table = str.maketrans(punctuation, punc_replace);\n",
        "    doco_clean = ' '.join([word.translate(trans_table) for word in doco_alphas.split(' ')]);\n",
        "    doco_clean = doco_clean.split(' ');\n",
        "    doco_clean = [word.lower() for word in doco_clean if len(word) > 0];\n",
        "    \n",
        "    return doco_clean;\n",
        "\n",
        "# Generate a cleaned reviews array from original review texts\n",
        "review_cleans = [clean_document(doc) for doc in reviews];\n",
        "sentences = [' '.join(r) for r in review_cleans]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4qjrFMcWxZk",
        "outputId": "c69f8bf4-68e6-4dd2-c14b-8ccfeb78060f"
      },
      "source": [
        "print(sentences[0:2])\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.backend import eval\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.convolutional import Conv1D,MaxPooling1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(sentences, y.values, test_size=0.20, random_state=42)\n",
        "\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "maxlen = 200\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i order of them and one of the item is bad quality is missing backup spring so i have to put a pcs of aluminum to make the battery work', 'bulk is always the less expensive way to go for products like these']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56hboHhQXrx4"
      },
      "source": [
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "\n",
        "# using GLOVE word embeddings\n",
        "embeddings_dictionary = dict()\n",
        "\n",
        "glove_file = open('glove.6B.100d.txt', encoding=\"utf8\")\n",
        "\n",
        "for line in glove_file:\n",
        "    records = line.split()\n",
        "    word = records[0]\n",
        "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
        "    embeddings_dictionary[word] = vector_dimensions\n",
        "glove_file.close()\n",
        "\n",
        "embedding_matrix = zeros((vocab_size, 100))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_dictionary.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5ExrKdEWEKr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db2a9faa-000e-4e31-8056-40b913bc2de9"
      },
      "source": [
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "\n",
        "deep_inputs = Input(shape=(maxlen,))\n",
        "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], trainable=False)(deep_inputs)\n",
        "LSTM_Layer_1 = LSTM(128, return_sequences=True)(embedding_layer)\n",
        "LSTM_Layer_2 = LSTM(128, return_sequences=False)(LSTM_Layer_1)\n",
        "#adding a dense layer with activation function of relu\n",
        "dense_layer_2 = Dense(5, activation='sigmoid')(LSTM_Layer_2)\n",
        "model = Model(inputs=deep_inputs, outputs=dense_layer_2)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "model.fit(X_train, y_train, batch_size=64, epochs=5, validation_data=(X_test, y_test))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "355/355 [==============================] - 319s 886ms/step - loss: 0.3481 - acc: 0.6960 - val_loss: 0.3095 - val_acc: 0.7050\n",
            "Epoch 2/5\n",
            "355/355 [==============================] - 315s 888ms/step - loss: 0.3084 - acc: 0.6994 - val_loss: 0.3086 - val_acc: 0.7050\n",
            "Epoch 3/5\n",
            "355/355 [==============================] - 310s 874ms/step - loss: 0.3081 - acc: 0.7025 - val_loss: 0.3094 - val_acc: 0.7050\n",
            "Epoch 4/5\n",
            "355/355 [==============================] - 312s 879ms/step - loss: 0.3155 - acc: 0.6983 - val_loss: 0.3082 - val_acc: 0.7050\n",
            "Epoch 5/5\n",
            "355/355 [==============================] - 311s 875ms/step - loss: 0.3085 - acc: 0.6987 - val_loss: 0.3080 - val_acc: 0.7050\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff2232b4890>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHNbs7gKgcH5",
        "outputId": "b80e9d81-9059-4f42-d368-181ca3dac63e"
      },
      "source": [
        "score = model.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy: %0.4f%%\" % (score[1]*100))\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "178/178 [==============================] - 22s 121ms/step - loss: 0.3080 - acc: 0.7050\n",
            "Test accuracy: 70.4959%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuUqJvNIuETx"
      },
      "source": [
        "## II RNN approach (removed stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUiRw7-Rr_cu",
        "outputId": "9a997453-889d-4281-cf82-94beb8b0295a"
      },
      "source": [
        "# with stopwords\n",
        "df = pd.read_csv('amazon_review_dataset.csv') #renamed\n",
        "df = df[df['reviews.rating'].notnull() & df['reviews.text'].notnull()]\n",
        "df= df[['reviews.rating','reviews.text']]\n",
        "\n",
        "df.rename(columns = {'reviews.rating':'rating', 'reviews.text':'text'}, inplace = True)\n",
        "df['text'][0]\n",
        "cleaned = df['text']\n",
        "print(cleaned[0])\n",
        "stops = stopwords.words('english')\n",
        "\n",
        "remove_punc = re.compile('[^a-z]+')\n",
        "def clean_text(sent):\n",
        "    sent = str(sent).lower()\n",
        "    sent = remove_punc.sub(' ', sent).strip()\n",
        "    filtered = [word for word in sent.split() if word not in stops]\n",
        "    sentence = \" \".join(filtered) #just joined -> laused\n",
        "  \n",
        "    #sentence = nltk.word_tokenize(sentence) #tokenized -> listid\n",
        "    return sentence\n",
        "\n",
        "\n",
        "clean_text(df['text'][0])\n",
        "reviews = [clean_text(sent) for sent in df['text']]"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I order 3 of them and one of the item is bad quality. Is missing backup spring so I have to put a pcs of aluminum to make the battery work.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "0U813IxnsVy_",
        "outputId": "170ec1c2-b985-4ab7-b7b8-80bf18b04152"
      },
      "source": [
        "df['text'] = reviews\n",
        "df.head()\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>order one item bad quality missing backup spri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>bulk always less expensive way go products like</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>well duracell price happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>seem work well name brand batteries much bette...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>batteries long lasting price great</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rating                                               text\n",
              "0       3  order one item bad quality missing backup spri...\n",
              "1       4    bulk always less expensive way go products like\n",
              "2       5                          well duracell price happy\n",
              "3       5  seem work well name brand batteries much bette...\n",
              "4       5                 batteries long lasting price great"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTZz5GN2sWFQ"
      },
      "source": [
        "y = pd.get_dummies(df.rating, prefix='rating_')\n",
        "def clean_document(doco):\n",
        "    punctuation = string.punctuation + '\\n\\n';\n",
        "    punc_replace = ''.join([' ' for s in punctuation]);\n",
        "    doco_clean = doco.replace('-', ' ');\n",
        "    doco_alphas = re.sub(r'\\W +', '', doco_clean)\n",
        "    trans_table = str.maketrans(punctuation, punc_replace);\n",
        "    doco_clean = ' '.join([word.translate(trans_table) for word in doco_alphas.split(' ')]);\n",
        "    doco_clean = doco_clean.split(' ');\n",
        "    doco_clean = [word.lower() for word in doco_clean if len(word) > 0];\n",
        "    \n",
        "    return doco_clean;\n",
        "\n",
        "# Generate a cleaned reviews array from original review texts\n",
        "#review_cleans = [clean_document(doc) for doc in reviews];\n",
        "#sentences = [' '.join(r) for r in review_cleans]\n",
        "sentences = [' '.join(r) for r in reviews]"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZbiUrIZspUX"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(reviews, y.values, test_size=0.20, random_state=42)\n",
        "\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "maxlen = 200\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2AwSN0GswmG"
      },
      "source": [
        "# using GLOVE word embeddings\n",
        "embeddings_dictionary = dict()\n",
        "\n",
        "glove_file = open('glove.6B.100d.txt', encoding=\"utf8\")\n",
        "\n",
        "for line in glove_file:\n",
        "    records = line.split()\n",
        "    word = records[0]\n",
        "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
        "    embeddings_dictionary[word] = vector_dimensions\n",
        "glove_file.close()\n",
        "\n",
        "embedding_matrix = zeros((vocab_size, 100))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_dictionary.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wmq4w8Nsx3ed",
        "outputId": "d67f2589-488d-4f38-9fd8-66f1934f6691"
      },
      "source": [
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "\n",
        "deep_inputs = Input(shape=(maxlen,))\n",
        "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], trainable=False)(deep_inputs)\n",
        "LSTM_Layer_1 = LSTM(128, return_sequences=True)(embedding_layer)\n",
        "LSTM_Layer_2 = LSTM(128, return_sequences=False)(LSTM_Layer_1)\n",
        "#adding a dense layer with activation function of relu\n",
        "dense_layer_2 = Dense(5, activation='sigmoid')(LSTM_Layer_2)\n",
        "model = Model(inputs=deep_inputs, outputs=dense_layer_2)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "model.fit(X_train, y_train, batch_size=64, epochs=5, validation_data=(X_test, y_test))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "355/355 [==============================] - 344s 958ms/step - loss: 0.3475 - acc: 0.6919 - val_loss: 0.3082 - val_acc: 0.7050\n",
            "Epoch 2/5\n",
            "355/355 [==============================] - 336s 947ms/step - loss: 0.3087 - acc: 0.7031 - val_loss: 0.3087 - val_acc: 0.7050\n",
            "Epoch 3/5\n",
            "355/355 [==============================] - 331s 933ms/step - loss: 0.3085 - acc: 0.7002 - val_loss: 0.3081 - val_acc: 0.7050\n",
            "Epoch 4/5\n",
            "355/355 [==============================] - 327s 921ms/step - loss: 0.3050 - acc: 0.7074 - val_loss: 0.3084 - val_acc: 0.7050\n",
            "Epoch 5/5\n",
            "355/355 [==============================] - 327s 920ms/step - loss: 0.3069 - acc: 0.7046 - val_loss: 0.3087 - val_acc: 0.7050\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff25f2e8fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx4i2uYJszU-",
        "outputId": "963d562a-39e8-40b6-ede3-f6bc49904dd1"
      },
      "source": [
        "score = model.evaluate(X_test, y_test)\n",
        "print(\"Test accuracy: %0.4f%%\" % (score[1]*100))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "178/178 [==============================] - 22s 121ms/step - loss: 0.3087 - acc: 0.7050\n",
            "Test accuracy: 70.4959%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUf6V47UuP5r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}